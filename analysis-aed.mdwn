% Deanonymisation attacks on the Tor network 2013-2014
% Alan Dawson
% December 2014

# Tor

Tor is a low latency anonymisation  and privacy platform for network traffic.  

- Low latency, in that it's usable for everyday browsing. 
- Anonymisation in that it seeks to prevent network operators identifying the source of traffic.
- Privacy in that it seeks to prevent network operators identifying the content of traffic.

# How does it work

The Tor client, known as a an Onion Proxy (OP) bootstraps itself at startup. This involves the following stages:- 

- The OP contacts the Tor Directory Authorities (DA), and downloads a list of the currently available Tor relays (OR) together with their exit node policies, public keys and other information.  
- The OP selects an exit node, that is suitable for the traffic it wants to send.
- The OP then selects an number of OR ( OR1, OR2 ... ) to create a circuit to the exit node.  In practice this is just 2 OR, an entrance, known as a Guard Node, and a Relay Node.
- The OP creates a circuit to the guard node.
- The OP extends the circuit to the relay, and from there extends it to the exit node.

In this way OP builds a circuit across 3 OR.  Each OR is only aware of the previous hop and destination hop.  

In practice a OP will build several circuits, with various relay and exit nodes, but will keep the same guard node ( entrance ) for extended periods of time.

# Attacks on Tor Clients

## Evil exit node

Unless the traffic from the destination is authenticated then an evil exit node can insert or alter any responses from the destination to the client. Examples of authenticated traffic are: 

- https traffic with certificate verification. This will provide end to end authentication and encryption of destination to the client
- downloading of data that has a cryptographically verifiable signature, where the signature can be verified via a different channel.  This would allow the exit node to see the traffic still, but the client would be able to tell verify the content.  Examples of this would be the downloading of packages from Windows Update.  The exit node would be able see which updates were being downloaded, but an attempt to tamper with them would invalidate cryptographic signatures.

Examples of unauthenticated traffic would include browsing over http, the use of internet relay chat and  Window Live Messenger.

## Correlation Attacks

If an attacker can track data entering and exiting the Tor network they can use the correlate the timing of data packets to deanonymise users.  For example an attacker could run enough Tor relays and exit nodes that the user selects the adversary as a guard node ( entrance ) and exit node. The Tor protocol attempts to prevent this in several ways.

-  Entrance or guard nodes are kept for long periods of time by Tor users. They are initially chosen at random, but they are kept. This limits the level of user profiling.
- Relays can be organised into "families". Tor users avoid using relays that are in the same family
- Users avoid relays that are in the same /16 IP subnet 

## Tor browser bundle exploit

A common error for users is to use the same browser on the Tor network as they do for everyday browsing. Websites will store small pieces of information to identify users called cookies to maintain state or to track for advertising purposes. When this browser is then used to visit websites across the Tor network, these same cookies will reveal the users identity.  

To prevent this the Tor project produces a customised version of the Firefox browser, known as the Tor Browser Bundle, which has most plugins, and cookies disabled. This customised verion of Firefox is vulnerable to similar exploits that other versions of Firefox are, and it's important that Tor users keep their versions of the Tor Browser Bundle up to date.


## Directory Authorities  compromise

The Tor network has 10 Directory Authorities. These contain a list of the currently active Tor relays, and other information that is required for an OP to bootstrap a circuit.  The directory authorities are hardcoded into the Tor client, they're updated hourly, and build a consensus over the state of the Tor network. Nine of these directory authorities act for the general Tor client, and one acts for Tor bridges.

If 5 of the directory authorities were taken over, then an attacker could control the view of the Tor network that clients received.  For example clients could be directed to select circuits where the nodes are all controlled by the attacker.  This would deanonymise Tor users.

As the directory authorities are geographically diversely located in different legal regimes it would be difficult for an attacker to do this.  However it was rumoured that this was about to take place in December 19th 2014 <https://blog.torproject.org/blog/possible-upcoming-attempts-disable-tor-network>.  It's been noted that collusion between the German and US states could remove 5 Directory Authorities.


# Tor hidden services

Tor hidden services allow a service operator to anonymise the location of the service. In standard use of Tor a destination is not able to discover the IP address of client. When a service is published as a hidden service, the IP address of the service provider is anonymous.

Hidden services are published as ".onion" addresses.  For example facebook publish <https://facebookcorewwwi.onion>, and the duckduckgo search engine publishes <http://3g2upl4pq6kufc4m.onion> 

The onion address is 80bit hash of the public key associated with the Tor hidden service, encoded in a 16 characters base 32 ( [a-z][2-7] ) format. As the onion address contains both the public key information as well as the name of the service it both identifies and authenticates the site.


## Tor hidden service protocol

The hidden service builds a Tor circuit to a number of "introduction points" (IntP).  The IntP publish information about the hidden service into a distributed hash table, shared amongst special Tor nodes known as HSDir ( Hidden Service Directories ).

When a client wishes to connect to a hidden service, it performs several tasks, all across Tor circuits.

1. looks up the IntP's and public key info for the hidden service from a HSDir server, and  chooses an OR to be a Rendezvous Point (RP)
1. Asks the IntP to contact the hidden service and tell it the RP
1. The HS makes a Tor circuit to the RP
1. The client makes a circuit to the RP

## Attacks on Tor hidden services


# Historic deanonymisation of Tor users 2013-2014

## Freedom Hosting August-September 2013

"Freedom hosting" was a service provider offering turnkey tor hidden service hosting. The company had achieved some notoriety in 2011 when Anonymous had attacked some Freedom Hosting sites for hosting child pornography. On 29 July 2013, Freedom Hosting's owner, Eric Eioan Marques, was arrested by the FBI on charges relating to the distribution of child pornography. Shortly afterwards in early August 2013 a large number of those Tor hidden services stopped serving their usual content, and instead started providing a web page saying they were down for maintenance. However, the maintenance web page had an embedded piece of Javascript, that exploited a vulnerability in versions of Firefox in old versions of the Tor Browser Bundle used at that time. It appears that all these sites were provided by Freedom Hosting.  It is worth noting that not all sites hosted by Freedom Hosting were criminal, however all were taken down used to deliver exploits to their users.

The security announcement to the Tor-announce mailing lists <https://lists.torproject.org/pipermail/tor-announce/2013-August/000089.html> details the discovery of the deanonymisation attack.

The vulnerability has been extensively analysed by Dr Gareth Owen of Portsmouth University, <https://ghowen.me/fbi-tor-malware-analysis/>. Owen notes that, "The malware phones home with identifying information from the user's computer and then crashes the firefox browser. In terms of sophistication, it's nothing special with no obfuscation and no new tricks that arent widely known other than the exploit. "

The exploit though is interesting as it records only 

1. the computer windows hostname 
1. the local IP address of the  computer  
1. the computers ethernet MAC address
1. a unique identifier linking these data to the web site accessed.

These were encoded into an HTTP request to an IP address in Virginia USA.  The HTTP request was generated by a raw windows socket. Unless the exploited computer was protected by a firewall or router that blocked non torified connections then the computers public IP address (i.e. that provided by its ISP ) would have been registered as the sending address

This data recorded is typical of a law enforcement CIPAV ( Computer Internet Protocol Address Verifier ), and  substantially different to a general malware attack.  Malware attacks are more generally interested in monetizing the victim. For example, copying banking details, sending spam email, downloading additional malware component to form bot nets. Law Enforcement wish to identify the user and preserve evidence.  Network card MAC addresses can be used to trace computer components through supply chains, public IP addresses can be used to identify ISP subscribers.  

Evidence has since come out that the NSA helped develop this attack under the codename "EgotisticalGiraffe" <http://www.theguardian.com/world/interactive/2013/oct/04/egotistical-giraffe-nsa-tor-document>

### Prevention of deanonymisation

Various steps would have prevented users from being deanonymised, these include. 

- Using current versions of the Tor Browser Bundle.
    - The vulnerability was fixed in the Tor Browser Bundle released June 26 2013 <https://blog.torproject.org/blog/new-tor-browser-bundles-and-tor-02414-alpha-packages> 
- Using a firewall or other method that prevented non-torified connections
    - Live CD's such as the TA(I)LS <https://tails.boum.org/> or whonix<https://www.whonix.org/> prevent non Tor traffic leaving.
- Using a non windows operating system
    - All Tor clients look similar to each other. They are difficult for network attackers to tell apart.  But as most users run Windows operating systems, attacks will most commonly target windows.  This attack did exactly that.
- Disabling Javascript.  
    - The Tor Browser Bundle comes with the "no script" plugin, **but** this is disabled by default. Disabling javascript would have prevented the code from running, but could affect usability of some web sites.

## Silk Road

The Silk Road was a Tor hidden service that provided an online market place for illegal drugs. It made use of bitcoins for payment and Tor hidden services to provide anonymity for the operator.

Ross Ulbricht was arrested on 2 October 2013, and at this time the Silk Road hidden service started showing a image from the FBI. 

The FBI complaint <https://www.cs.columbia.edu/~smb/UlbrichtCriminalComplaint.pdf>  that resulted in the arrest of Ubricht does not contain information over how the Silk Road Marketplace Server was located, however it does contain much information from the Silk Road Markeplace server that links Ulbricht to the Silk Road, including...

- IP addresses of commercial VPN providers coded into the marketplace application.  The commercial VPN provider provided subscriber information to Law enforcement
- SSH public keys

Additionally circumstantial historical evidence around the initial marketing, code development, and social media profiles were used to link Ulbricht with the adminstrator of the Silk Road.

The FBI later revealed how they deanonymised the Silk Road server <http://ia700603.us.archive.org/21/items/gov.uscourts.nysd.422824/gov.uscourts.nysd.422824.57.0.pdf>.  In it a computer security expert describes the process of fuzzing input into login fields on the Silk Road Marketplace web application, recording of the output, and gathering packet captures of traffic. In June 2013 this resulted in an IP address associated with a server in Iceland was discovered.  

The FBI arranged for the machine to be imaged, which where then forensically examined, leading to the arrest of Ulbricht and takedown of the site.

### Prevention of deaonymisation

The code that ran the Silk Road application had at various times had debug statements left in it that revealed identifying information.  To successfully run a hidden service the application and associated stack ( web server, operating system etc ... ) should not reveal any IP addressing information. A simple way to resolve this would be to have the public hidden service act as a proxy and forward requests on to a second machine over a private network.  The application logic runs on the second machine, and any failure in that would only return a private IP address.



## Harvard Bomb Threat

On 16 December 2013 Harvard University received a bomb threat via the <https://www.guerrillamail.com> email provider. Shortly afterwords a Harvard student was charged. He had used the university wireless network to connect to the Tor network and send the email. Whilst the full details of his deanonymisation are not available some features stand out.

- The subject authenticated against the university wireless network
- It's common on public and authenticated wireless networks to have a high level of logging of source  and destination IP addresses and ports 
- Email often contains information regarding sending IP addresses and times in header information

### Example email header from  https://www.guerrillamail.com

This is an example of a guerrillamail.com email header, with the destination email address and server obfuscated. Note that the service provides an additional header `X-Originating-IP: [72.52.75.27]` to provide a way of tracking abuse.

~~~~~~~~

Return-path: <djajppp+fku4n0@guerrillamail.com>
Envelope-to: xxxxxxx@example.org
Delivery-date: Sat, 27 Dec 2014 18:19:40 +0000
Received: from mail.guerrillamail.com ([198.143.169.10] helo=guerrillamail.com)
        by mx.example.org with esmtp (Exim 4.80)
        (envelope-from <djajppp+fku4n0@guerrillamail.com>)
        id 1Y4vxj-0002LQ-1U
        for xxxxxxx@example.org; Sat, 27 Dec 2014 18:19:40 +0000 
Received: by 198.143.169.10 with HTTP; Sat, 27 Dec 2014 18:18:59 +0000
MIME-Version: 1.0
Message-ID: <94ee9dcba5ba1570d400693e9e61b42a567@guerrillamail.com>
Date: Sat, 27 Dec 2014 18:18:59 +0000
To: "xxxxxx@example.org" <xxxxxx@example.org>
From: djajppp+fku4n0@guerrillamail.com
Subject: test
X-Originating-IP: [72.52.75.27]


~~~~~~~~

The Tor project provides the **exonerator** service, which is historical information on Tor nodes and their exit policies. This shows that 72.52.75.27 was acting as an exit node with a policy that allowed access to the service described in the email headers (i.e. webmail )

<https://exonerator.torproject.org/?timestamp=2014-12-27&ip=72.52.75.27&targetaddr=198.143.169.10&targetport=80#exit>

Given that the email was sent from the Tor client, Harvard university network administrators could look at the outgoing traffic logs, and determine if any users had accessed the Tor network at the time that the message was sent.  A current consensus can be downloaded from a Tor directory authority, and this can be simply parsed to generate a list of all known tor relays.  For example <http://193.23.244.244/tor/status-vote/current/consensus>. Traffic logs can be searched for outgoing connections to IP addresses in the Tor network.

It is possible that the network administrators had already automated the process of logging traffic to the Tor network.  A small bash shell script, run from a cron job, could automatically generate Snort rules.  For example: 

~~~~~~~

curl -s http://193.23.244.244/tor/status-vote/current/consensus  | \
grep ^r | awk '{print $7}' | sort  | \
uniq | xargs -i{} echo 'alert tcp any any ->' {}

~~~~~~~

which would have simplified the task for the Network Administrators, as they would already have logs of the required outgoing traffic.  They could have matched hosts who accessed the Tor network with other logs, such as DHCP logs, RADIUS logs, to identify the possible users, and been able to correlate the outgoing traffic with the email header timings.

After gathering a list of possible suspects on campus, it's likely that ordinary policing techniques, will have caused the suspect to confess to the act.

### Prevention of deanonymisation

In this case the poor operational security and unsophistication of the user made it simple for law enforcement to identify him.

- Using the Harvard network to attack it.
    - This allowed timing information to be correlated and identify the subject
- Not scheduling the delivery of the email.
    - This again allowed timing information to correlated.

## Relay Early 

## Operation Onymous / Silk Road 2
